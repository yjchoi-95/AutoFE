{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a563f7-134f-48d4-a345-508faf08c477",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184bf49d-56d7-4fe0-ba62-788ae1366345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44919a-34e8-4d61-a242-50721e16666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b601ae91-01e8-4451-8314-5cb494fb6345",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "* url: https://www.openml.org/search?type=study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b2e4e2-a03a-4cd4-a8d2-c6e92e1ae6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PC0\\\\Documents\\\\GitHub\\\\AutoFE\\\\ipynb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e021e9-67eb-4c7d-ab5b-496b5b0e13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../datasets/\"\n",
    "file_list = glob(data_path + \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1874ea6-f3a6-48fc-84ae-619e3337108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openml_586.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = file_list[0].split(\"\\\\\")[1]\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "169069f1-ea91-487c-8f0d-e09f6e59fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml_586\n",
      "openml_589\n",
      "openml_607\n",
      "openml_616\n",
      "openml_618\n",
      "openml_620\n",
      "openml_637\n",
      "rmftsa_ladata\n",
      "steel_plate\n",
      "wine_quality_red\n",
      "wine_quality_white\n"
     ]
    }
   ],
   "source": [
    "for file_path in glob(data_path + \"*\"):\n",
    "    file_name = file_path.split(\"\\\\\")[1]\n",
    "    file_name = file_name.split(\".csv\")[0]\n",
    "    globals()[file_name] = pd.read_csv(file_path)\n",
    "    \n",
    "    if \"rmftsa_ladata\" in file_name:\n",
    "        globals()[file_name].rename(columns = {\"Respiratory_Mortality\":\"target\"}, inplace = True)\n",
    "    else:\n",
    "        globals()[file_name].rename(columns = {globals()[file_name].columns[globals()[file_name].shape[1]-1]:\"target\"}, inplace = True)\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920ca46-d159-47f7-a1f2-930507387d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "293cd4da-94b4-4a4e-86ba-88d64f4dd7a1",
   "metadata": {},
   "source": [
    "## Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598176b4-4581-41d9-8d51-8c49eb66fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import make_scorer, SCORERS\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from ngboost import NGBRegressor, NGBClassifier\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fa721d-64db-4ca7-aaa7-57693481b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_reg = XGBRegressor()\n",
    "model_lgbm_reg = LGBMRegressor()\n",
    "model_rf_reg = RandomForestRegressor()\n",
    "model_ngb_reg = NGBRegressor()\n",
    "\n",
    "model_ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2012424d-bd6d-4535-bf53-3f9ffbe1a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_function(data) :\n",
    "    data_x = data.loc[:, ~data.columns.isin(['target'])]\n",
    "    data_y = data.loc[:, data.columns.isin(['target'])]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a282458a-6b23-4095-9c90-20ebf9ce3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [openml_586, openml_589, openml_607, openml_616, openml_618, openml_620, openml_637, rmftsa_ladata]#, wine_quality_red, wine_quality_white]\n",
    "data_keys = [\"openml_586\", \"openml_589\", \"openml_607\", \"openml_616\", \"openml_618\", \"openml_620\", \"openml_637\", \"rmftsa_ladata\"]#, \"wine_quality_red\", \"wine_quality_white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d674a7cf-cb2f-437b-ba58-73224ce7b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rae(y_true, y_pred):\n",
    "    y_true = np.array(y_true).squeeze()\n",
    "    y_pred = np.array(y_pred).squeeze()\n",
    "    return 1 - (np.sum(np.abs(y_pred-y_true)) / np.sum(np.abs(np.mean(y_true) - y_true)))\n",
    "\n",
    "def total_cv_results(model, data_keys, datasets):\n",
    "    for keys, data in zip(data_keys, datasets):\n",
    "        X_train, X_test, y_train, y_test = split_function(data)\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=make_scorer(rae, greater_is_better=True))\n",
    "        print(keys, np.mean(results))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1d533f-4128-4a54-88ba-e14f25468002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml_586 0.6950885014153116\n",
      "openml_589 0.6892227791803537\n",
      "openml_607 0.6827517436696967\n",
      "openml_616 0.5972735776128185\n",
      "openml_618 0.6739238340101057\n",
      "openml_620 0.678826725913838\n",
      "openml_637 0.5617752310170727\n",
      "rmftsa_ladata 0.2543937480673959\n"
     ]
    }
   ],
   "source": [
    "total_cv_results(model_xgb_reg, data_keys, data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4cd777-7fdd-41df-acff-c42958d552d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2933967504320455"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate baseline score\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "X_train, X_test, y_train, y_test = split_function(rmftsa_ladata)\n",
    "results = cross_val_score(model_ridge, X_train, y_train, cv=kfold, scoring=make_scorer(rae, greater_is_better=True))\n",
    "baseline_score = np.mean(results); baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36828b1-8ffe-47b7-af78-6df3669bf9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb3bcb5-3e04-478c-818a-fecab6ce0390",
   "metadata": {},
   "source": [
    "### Make states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33fda8-3aa3-404f-ab2d-06a2f8987c29",
   "metadata": {},
   "source": [
    "* correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13bc7321-2a78-4f85-942b-d80a8d986dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4761351-337a-4e1a-9922-503b7e0ef2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corr_state(data_x, data_y):\n",
    "    data_x = np.array(data_x)\n",
    "    corr_state_list = []\n",
    "    for col in range(data_x.shape[1]) :\n",
    "        corr_state_list.append(pearsonr(np.array(data_x[:, col]).squeeze(), np.array(data_y).squeeze())[0])\n",
    "    return np.array(corr_state_list)\n",
    "\n",
    "def make_median_state(data_x, data_y): \n",
    "    under_median_idx = np.where(np.array(data_y).squeeze() < np.median(np.array(data_y)))[0]\n",
    "    over_median_idx = np.where(np.array(data_y).squeeze() >= np.median(np.array(data_y)))[0]\n",
    "    \n",
    "    under_median_state = np.mean(np.array(data_x)[under_median_idx,:], axis = 0)\n",
    "    over_median_state = np.mean(np.array(data_x)[over_median_idx,:], axis = 0)\n",
    "    \n",
    "    return np.vstack([over_median_state, under_median_state])\n",
    "\n",
    "def make_state(data_x, data_y):\n",
    "    corr_state = make_corr_state(data_x, data_y)\n",
    "    median_state = make_median_state(data_x, data_y)\n",
    "    total_state = np.vstack([corr_state, median_state])\n",
    "    total_state[np.isnan(total_state)] = 0\n",
    "    \n",
    "    return total_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07259ca4-6726-4be8-8865-c3ca309db098",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_state = make_state(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e629d7-525d-4227-a77d-262c73738117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff270e5-456a-47b4-bf36-b851b97d763c",
   "metadata": {},
   "source": [
    "## Get transformation rules\n",
    "\n",
    "- order-1 transformation: log, round, sigmoid, tanh, square, root, zscore, min-max normalization\n",
    "- order-2 transformation: sum, difference, product, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed5eff87-5392-418b-bdb0-7941aa8051ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, robust_scale\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 +np.exp(-x))\n",
    "\n",
    "def origin(x):\n",
    "    return x\n",
    "\n",
    "transformations = ['log', 'sigmoid', 'tanh', 'square', 'root', 'min_max', 'zscore', 'done']\n",
    "operations = [np.log, sigmoid, np.tanh, np.square, np.sqrt, minmax_scale, robust_scale, origin]\n",
    "oper_dict = {x:y for x,y in zip(transformations, operations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992a90e-4451-4263-a4ad-9fe143549f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "943de3f3-9c0c-43ef-972f-2c7ed27e9852",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74752e49-4263-4e21-a896-00e311054998",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd().split(\"ipynb\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebcf1cb9-f814-49f9-b631-97517bb0ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = root_path +  \"\\\\model_weights_rnd\\\\\"\n",
    "state_path = root_path +  \"\\\\state_rnd\\\\\"\n",
    "\n",
    "if not os.path.isdir(weight_path) :\n",
    "    os.mkdir(weight_path)\n",
    "    \n",
    "if not os.path.isdir(state_path) :\n",
    "    os.mkdir(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27baaf7a-dd0e-401a-b685-98939043a368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfac583-d502-436d-bd4f-1f54d1847a1f",
   "metadata": {},
   "source": [
    "* RND network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92de0f76-60cf-444b-b234-17c9d54470e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RND_network(total_state) :\n",
    "    ## target network\n",
    "    input_layer = tf.keras.Input(shape = (total_state.shape[0], total_state.shape[1]))\n",
    "    hidden_x = tf.keras.layers.Conv1D(32, 3, activation = \"selu\")(input_layer)\n",
    "    flatten_x = tf.keras.layers.Flatten()(hidden_x)\n",
    "    output_x = tf.keras.layers.Dense(4)(flatten_x)\n",
    "    rnd_network = tf.keras.Model(inputs = input_layer, outputs = output_x)\n",
    "    \n",
    "    return rnd_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5fefc2a-6f73-4f17-9a46-290ffc5f0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_network = RND_network(total_state)\n",
    "target_network.trainable = False\n",
    "if os.path.isfile(weight_path + \"target_network.h5\") :\n",
    "    target_network.load_weights(weight_path+\"target_network.h5\")\n",
    "else :\n",
    "    target_network.save_weights(weight_path+\"target_network.h5\")\n",
    "\n",
    "prediction_network = RND_network(total_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd001dc-b7f0-48b1-8ccc-e1d40cc36a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e0c8e20-eddd-42aa-97ed-46926e4369fa",
   "metadata": {},
   "source": [
    "* A2C network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c28d6766-9b3a-40c1-9f6c-671010455d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions network\n",
    "actor_inputs = tf.keras.Input(shape = (total_state.shape[0], total_state.shape[1]))\n",
    "conv_1d_layer = tf.keras.layers.Conv1D(32, 2, activation = \"selu\")(actor_inputs)\n",
    "flatten_layer = tf.keras.layers.Flatten()(conv_1d_layer)\n",
    "shared_x1 = tf.keras.layers.Dense(128, activation = \"selu\")(flatten_layer)\n",
    "shared_x2 = tf.keras.layers.Dense(32, activation = \"selu\")(shared_x1)\n",
    "actor_outputs_actions = tf.keras.layers.Dense(len(transformations), activation = \"softmax\")(shared_x2)\n",
    "\n",
    "# critic network\n",
    "conv_1d_layer_critic = tf.keras.layers.Conv1D(32, 3, activation = \"selu\")(actor_inputs)\n",
    "flatten_layer_critic = tf.keras.layers.Flatten()(conv_1d_layer_critic)\n",
    "critic_x = tf.keras.layers.Dense(16, activation = \"selu\")(flatten_layer_critic)\n",
    "critic_output = tf.keras.layers.Dense(1, activation = \"tanh\")(critic_x)\n",
    "\n",
    "A2C = tf.keras.Model(inputs = actor_inputs, outputs = [actor_outputs_actions, critic_output])\n",
    "A2C_params = A2C.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f8704-8b8d-4bb9-8837-613b7f4da2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6fc5c27-ea1b-4b81-acc6-b85d4c187dab",
   "metadata": {},
   "source": [
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9bbc1067-dc35-43ba-9835-d152f81fda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation, value = A2C(np.expand_dims(total_state, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "675339fa-ef0d-4bb7-8cf2-3118e8536cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(model, state, data):\n",
    "    operation, value = model(state)\n",
    "    action = np.argmax(operation)\n",
    "    select_action = transformations[action]\n",
    "    output = oper_dict[select_action](data)\n",
    "    output = pd.DataFrame(output, columns = data.columns)\n",
    "    output.replace(np.NaN, np.nanmean(output), inplace = True)\n",
    "    \n",
    "    return output, select_action, operation, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "390d262f-2262-46cb-a694-1e85df388a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'root'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, action, operation, value = get_action(A2C, np.expand_dims(total_state, 0), X_train); action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b37f1c83-27a6-4df1-872c-6c7605edeea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0002588857068009931"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_val_score(model_ridge, next_state, y_train, cv=kfold, scoring=make_scorer(rae, greater_is_better=True))\n",
    "reward = np.mean(results) - baseline_score; reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff448544-971f-49e4-993c-9d4721d0ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35305896-61cc-4ac3-8d63-d585ecc9590c",
   "metadata": {},
   "source": [
    "variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb8455-4e49-4cd4-9e7c-fe984a1bd4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ed6d4d-3f4e-4b09-ae83-2c99bbf26156",
   "metadata": {},
   "source": [
    "### Make env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6e4314a-44ef-427b-befb-0330fdb83938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(model, state, data):\n",
    "    operation, value = model(state)\n",
    "    action = np.argmax(operation)\n",
    "    select_action = transformations[action]\n",
    "    \n",
    "    return select_action, operation, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "442ce14f-c9b2-453b-bb42-90d6aa1ac56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(episode_buffer, t, discount_factor = 0.99) :\n",
    "    gain_ = np.sum([value[2] * discount_factor ** (idx) for idx, value in enumerate(list(episode_buffer)[t:])])\n",
    "    return gain_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b96d1007-d8dc-481f-b39b-ca661d95d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "\n",
    "import gym\n",
    "\n",
    "class automated_feature_env(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, target_model, data_x, data_y, state_dims, action_dims, oper_dict, baseline_score): \n",
    "        super(automated_feature_env, self).__init__()\n",
    "        \n",
    "        self.target_model = target_model\n",
    "        self.data_x = data_x\n",
    "        self.next_raw = data_x\n",
    "        self.data_y = data_y\n",
    "        self.state_dims = state_dims\n",
    "        self.action_dims = action_dims\n",
    "        self.oper_dict = oper_dict\n",
    "        self.baseline_score = baseline_score\n",
    "        \n",
    "        self.action_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=1,\n",
    "            shape=(self.action_dims,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(self.state_dims,),  # Passt sich damit automatisch an die Beobachtung an\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "    def reset(self):\n",
    "        observation = self._getObs()\n",
    "        self.next_raw = self.data_x\n",
    "        \n",
    "        return observation\n",
    "\n",
    "    def step(self, actions):\n",
    "        next_raw = self.oper_dict[actions](self.next_raw)\n",
    "        next_raw = pd.DataFrame(next_raw, columns = self.data_x.columns)\n",
    "        next_raw.replace(np.NaN, np.nanmean(next_raw), inplace = True)\n",
    "        \n",
    "        min_mark = 0\n",
    "        max_mark = 3\n",
    "\n",
    "        if np.sum(np.sum(np.isinf(next_raw))) > 0:\n",
    "            temp_min = np.min(np.min(next_raw.replace(-np.inf, min_mark)))\n",
    "            if temp_min < min_mark:\n",
    "                next_raw.replace(-np.inf, temp_min, inplace = True)\n",
    "            else:\n",
    "                next_raw.replace(-np.inf, min_mark, inplace = True)\n",
    "\n",
    "            temp_max = np.max(np.max(next_raw.replace(np.inf, max_mark)))\n",
    "            if temp_max > max_mark:\n",
    "                next_raw.replace(np.inf, temp_max, inplace = True)\n",
    "            else:\n",
    "                next_raw.replace(np.inf, max_mark, inplace = True)\n",
    "        \n",
    "        self.next_raw = next_raw\n",
    "        \n",
    "        observation = make_state(next_raw, self.data_y)\n",
    "        reward, dones = self._calcRewardDones(actions)\n",
    "        \n",
    "        return observation, reward, dones, {}\n",
    "    \n",
    "    def _calcRewardDones(self, actions):\n",
    "        if actions == \"done\":\n",
    "            dones = True\n",
    "        else: \n",
    "            dones = False\n",
    "        \n",
    "        results = cross_val_score(self.target_model, self.next_raw, self.data_y, cv=kfold, scoring=make_scorer(rae, greater_is_better=True))\n",
    "        reward = np.mean(results) - self.baseline_score\n",
    "        \n",
    "        return reward, dones\n",
    "\n",
    "    def _getObs(self):\n",
    "        return make_state(self.data_x, self.data_y)\n",
    "    \n",
    "    def make_corr_state(self, data_x, data_y):\n",
    "        data_x = np.array(data_x)\n",
    "        corr_state_list = []\n",
    "        for col in range(data_x.shape[1]) :\n",
    "            corr_state_list.append(pearsonr(np.array(data_x[:, col]).squeeze(), np.array(data_y).squeeze())[0])\n",
    "        return np.array(corr_state_list)\n",
    "\n",
    "    def make_median_state(self, data_x, data_y): \n",
    "        under_median_idx = np.where(np.array(data_y).squeeze() < np.median(np.array(data_y)))[0]\n",
    "        over_median_idx = np.where(np.array(data_y).squeeze() >= np.median(np.array(data_y)))[0]\n",
    "\n",
    "        under_median_state = np.mean(np.array(data_x)[under_median_idx,:], axis = 0)\n",
    "        over_median_state = np.mean(np.array(data_x)[over_median_idx,:], axis = 0)\n",
    "        return np.vstack([over_median_state, under_median_state])\n",
    "\n",
    "    def make_state(self, data_x, data_y):\n",
    "        corr_state = make_corr_state(data_x, data_y)\n",
    "        median_state = make_median_state(data_x, data_y)\n",
    "        total_state = np.vstack([corr_state, median_state])\n",
    "        total_state[np.isnan(total_state)] = 0\n",
    "        return total_state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def seed(self, seed=None) -> None:\n",
    "        pass\n",
    "    \n",
    "    def get_state(self):\n",
    "        observation = self.make_state(self.next_raw, self.data_y)\n",
    "        return pd.DataFrame(observation, columns = self.data_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "871de62f-b1cb-4440-816b-3314c9fc0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dims = total_state.shape[1]\n",
    "action_dims = len(transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "af4c6383-5de4-4de1-be15-6fae2e01b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = automated_feature_env(model_ridge, X_train, y_train, state_dims, action_dims, oper_dict, baseline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21779446-c38b-4b2e-aeda-2e1b917c3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f9be188-a78e-4641-9f5a-cb49a845e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episode = 100\n",
    "discount_factor = 0.99\n",
    "replay_buffer = deque(maxlen = 120000)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "23e23a7e-aa72-49a9-a80f-f3a215a8e324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode : 0\n",
      "log\n",
      "zscore\n",
      "done\n",
      "epi: 0 | total_scores: -0.025307204574346542 | total_int_scores: 3.158153533935547 |\n",
      "episode : 1\n",
      "log\n",
      "zscore\n",
      "done\n",
      "epi: 1 | total_scores: -0.0375409796833992 | total_int_scores: 1.9347763061523438 |\n",
      "episode : 2\n",
      "log\n",
      "zscore\n",
      "done\n",
      "epi: 2 | total_scores: -0.03528357297182083 | total_int_scores: 2.1605167388916016 |\n",
      "episode : 3\n",
      "log\n",
      "zscore\n",
      "done\n",
      "epi: 3 | total_scores: -0.03564993664622307 | total_int_scores: 2.12388014793396 |\n",
      "episode : 4\n",
      "log\n",
      "log\n",
      "done\n",
      "epi: 4 | total_scores: -0.369139164686203 | total_int_scores: 1.188631296157837 |\n",
      "episode : 5\n",
      "log\n",
      "done\n",
      "epi: 5 | total_scores: -0.08441072702407837 | total_int_scores: 0.3295130729675293 |\n",
      "episode : 6\n",
      "log\n",
      "done\n",
      "epi: 6 | total_scores: -0.08431490510702133 | total_int_scores: 0.3390953540802002 |\n",
      "episode : 7\n",
      "log\n",
      "done\n",
      "epi: 7 | total_scores: -0.0837787613272667 | total_int_scores: 0.3927094340324402 |\n",
      "episode : 8\n",
      "log\n",
      "done\n",
      "epi: 8 | total_scores: -0.08483757823705673 | total_int_scores: 0.28682804107666016 |\n",
      "episode : 9\n",
      "log\n",
      "done\n",
      "epi: 9 | total_scores: -0.08579954504966736 | total_int_scores: 0.1906317174434662 |\n",
      "episode : 10\n",
      "log\n",
      "done\n",
      "epi: 10 | total_scores: -0.08465415239334106 | total_int_scores: 0.30517062544822693 |\n",
      "episode : 11\n",
      "log\n",
      "done\n",
      "epi: 11 | total_scores: -0.08582286536693573 | total_int_scores: 0.18829914927482605 |\n",
      "episode : 12\n",
      "log\n",
      "done\n",
      "epi: 12 | total_scores: -0.08592210710048676 | total_int_scores: 0.17837557196617126 |\n",
      "episode : 13\n",
      "log\n",
      "done\n",
      "epi: 13 | total_scores: -0.08553016930818558 | total_int_scores: 0.21756872534751892 |\n",
      "episode : 14\n",
      "log\n",
      "done\n",
      "epi: 14 | total_scores: -0.08634059131145477 | total_int_scores: 0.13652703166007996 |\n",
      "episode : 15\n",
      "log\n",
      "done\n",
      "epi: 15 | total_scores: -0.08639810234308243 | total_int_scores: 0.13077574968338013 |\n",
      "episode : 16\n",
      "log\n",
      "done\n",
      "epi: 16 | total_scores: -0.08607489615678787 | total_int_scores: 0.16309624910354614 |\n",
      "episode : 17\n",
      "log\n",
      "done\n",
      "epi: 17 | total_scores: -0.08661791682243347 | total_int_scores: 0.10879446566104889 |\n",
      "episode : 18\n",
      "log\n",
      "done\n",
      "epi: 18 | total_scores: -0.08694535493850708 | total_int_scores: 0.07605089992284775 |\n",
      "episode : 19\n",
      "log\n",
      "done\n",
      "epi: 19 | total_scores: -0.0863620862364769 | total_int_scores: 0.13437706232070923 |\n",
      "episode : 20\n",
      "log\n",
      "done\n",
      "epi: 20 | total_scores: -0.08706861734390259 | total_int_scores: 0.06372367590665817 |\n",
      "episode : 21\n",
      "log\n",
      "done\n",
      "epi: 21 | total_scores: -0.08684869110584259 | total_int_scores: 0.08571697771549225 |\n",
      "episode : 22\n",
      "log\n",
      "done\n",
      "epi: 22 | total_scores: -0.08689169585704803 | total_int_scores: 0.08141598850488663 |\n",
      "episode : 23\n",
      "log\n",
      "done\n",
      "epi: 23 | total_scores: -0.08706951141357422 | total_int_scores: 0.06363466382026672 |\n",
      "episode : 24\n",
      "log\n",
      "done\n",
      "epi: 24 | total_scores: -0.08706764876842499 | total_int_scores: 0.06382107734680176 |\n",
      "episode : 25\n",
      "log\n",
      "done\n",
      "epi: 25 | total_scores: -0.08708584308624268 | total_int_scores: 0.06200149282813072 |\n",
      "episode : 26\n",
      "log\n",
      "done\n",
      "epi: 26 | total_scores: -0.08731325715780258 | total_int_scores: 0.039260126650333405 |\n",
      "episode : 27\n",
      "log\n",
      "done\n",
      "epi: 27 | total_scores: -0.08709101378917694 | total_int_scores: 0.061484284698963165 |\n",
      "episode : 28\n",
      "log\n",
      "done\n",
      "epi: 28 | total_scores: -0.08744826912879944 | total_int_scores: 0.025759097188711166 |\n",
      "episode : 29\n",
      "log\n",
      "done\n",
      "epi: 29 | total_scores: -0.08729523420333862 | total_int_scores: 0.04106255620718002 |\n",
      "episode : 30\n",
      "log\n",
      "done\n",
      "epi: 30 | total_scores: -0.08732786774635315 | total_int_scores: 0.03779932111501694 |\n",
      "episode : 31\n",
      "log\n",
      "done\n",
      "epi: 31 | total_scores: -0.08747024834156036 | total_int_scores: 0.02356168068945408 |\n",
      "episode : 32\n",
      "log\n",
      "done\n",
      "epi: 32 | total_scores: -0.08737650513648987 | total_int_scores: 0.03293519467115402 |\n",
      "episode : 33\n",
      "log\n",
      "done\n",
      "epi: 33 | total_scores: -0.08746805787086487 | total_int_scores: 0.02377999946475029 |\n",
      "episode : 34\n",
      "log\n",
      "done\n",
      "epi: 34 | total_scores: -0.0874955803155899 | total_int_scores: 0.02102724090218544 |\n",
      "episode : 35\n",
      "log\n",
      "done\n",
      "epi: 35 | total_scores: -0.08750226348638535 | total_int_scores: 0.020359458401799202 |\n",
      "episode : 36\n",
      "log\n",
      "done\n",
      "epi: 36 | total_scores: -0.08758912980556488 | total_int_scores: 0.01167236641049385 |\n",
      "episode : 37\n",
      "log\n",
      "done\n",
      "epi: 37 | total_scores: -0.08749501407146454 | total_int_scores: 0.021083995699882507 |\n",
      "episode : 38\n",
      "log\n",
      "done\n",
      "epi: 38 | total_scores: -0.08760154247283936 | total_int_scores: 0.010431553237140179 |\n",
      "episode : 39\n",
      "log\n",
      "done\n",
      "epi: 39 | total_scores: -0.08755860477685928 | total_int_scores: 0.014725206419825554 |\n",
      "episode : 40\n",
      "log\n",
      "done\n",
      "epi: 40 | total_scores: -0.0875772088766098 | total_int_scores: 0.012865392491221428 |\n",
      "episode : 41\n",
      "log\n",
      "done\n",
      "epi: 41 | total_scores: -0.08762307465076447 | total_int_scores: 0.008278864435851574 |\n",
      "episode : 42\n",
      "log\n",
      "done\n",
      "epi: 42 | total_scores: -0.08759334683418274 | total_int_scores: 0.011251132003962994 |\n",
      "episode : 43\n",
      "log\n",
      "done\n",
      "epi: 43 | total_scores: -0.08762863278388977 | total_int_scores: 0.007722821086645126 |\n",
      "episode : 44\n",
      "log\n",
      "done\n",
      "epi: 44 | total_scores: -0.0875970870256424 | total_int_scores: 0.010876832529902458 |\n",
      "episode : 45\n",
      "log\n",
      "done\n",
      "epi: 45 | total_scores: -0.0876234918832779 | total_int_scores: 0.00823662243783474 |\n",
      "episode : 46\n",
      "log\n",
      "done\n",
      "epi: 46 | total_scores: -0.0876283347606659 | total_int_scores: 0.0077528031542897224 |\n",
      "episode : 47\n",
      "log\n",
      "done\n",
      "epi: 47 | total_scores: -0.08763042837381363 | total_int_scores: 0.007543206214904785 |\n",
      "episode : 48\n",
      "log\n",
      "done\n",
      "epi: 48 | total_scores: -0.0876503437757492 | total_int_scores: 0.005550982430577278 |\n",
      "episode : 49\n",
      "log\n",
      "done\n",
      "epi: 49 | total_scores: -0.08764912933111191 | total_int_scores: 0.0056725130416452885 |\n",
      "episode : 50\n",
      "log\n",
      "done\n",
      "epi: 50 | total_scores: -0.08765469491481781 | total_int_scores: 0.005116443149745464 |\n",
      "episode : 51\n",
      "log\n",
      "done\n",
      "epi: 51 | total_scores: -0.08766120672225952 | total_int_scores: 0.00446506729349494 |\n",
      "episode : 52\n",
      "log\n",
      "done\n",
      "epi: 52 | total_scores: -0.0876605212688446 | total_int_scores: 0.004533871077001095 |\n",
      "episode : 53\n",
      "log\n",
      "done\n",
      "epi: 53 | total_scores: -0.08766516298055649 | total_int_scores: 0.004069795832037926 |\n",
      "episode : 54\n",
      "log\n",
      "done\n",
      "epi: 54 | total_scores: -0.0876641720533371 | total_int_scores: 0.004168713465332985 |\n",
      "episode : 55\n",
      "log\n",
      "done\n",
      "epi: 55 | total_scores: -0.08766359090805054 | total_int_scores: 0.004226190038025379 |\n",
      "episode : 56\n",
      "log\n",
      "done\n",
      "epi: 56 | total_scores: -0.08767104148864746 | total_int_scores: 0.0034818195272237062 |\n",
      "episode : 57\n",
      "log\n",
      "done\n",
      "epi: 57 | total_scores: -0.08765938878059387 | total_int_scores: 0.004646954592317343 |\n",
      "episode : 58\n",
      "log\n",
      "done\n",
      "epi: 58 | total_scores: -0.08767205476760864 | total_int_scores: 0.0033803568221628666 |\n",
      "episode : 59\n",
      "log\n",
      "done\n",
      "epi: 59 | total_scores: -0.08766888082027435 | total_int_scores: 0.003697978798300028 |\n",
      "episode : 60\n",
      "log\n",
      "done\n",
      "epi: 60 | total_scores: -0.08766011893749237 | total_int_scores: 0.004573700949549675 |\n",
      "episode : 61\n",
      "log\n",
      "done\n",
      "epi: 61 | total_scores: -0.08766333758831024 | total_int_scores: 0.004252145998179913 |\n",
      "episode : 62\n",
      "log\n",
      "done\n",
      "epi: 62 | total_scores: -0.0876835286617279 | total_int_scores: 0.00223262095823884 |\n",
      "episode : 63\n",
      "log\n",
      "done\n",
      "epi: 63 | total_scores: -0.08767309784889221 | total_int_scores: 0.003275500610470772 |\n",
      "episode : 64\n",
      "log\n",
      "done\n",
      "epi: 64 | total_scores: -0.08767668902873993 | total_int_scores: 0.002916560275480151 |\n",
      "episode : 65\n",
      "log\n",
      "done\n",
      "epi: 65 | total_scores: -0.08767691999673843 | total_int_scores: 0.0028939403127878904 |\n",
      "episode : 66\n",
      "log\n",
      "done\n",
      "epi: 66 | total_scores: -0.08769260346889496 | total_int_scores: 0.0013249363983049989 |\n",
      "episode : 67\n",
      "log\n",
      "done\n",
      "epi: 67 | total_scores: -0.08767344057559967 | total_int_scores: 0.0032421257346868515 |\n",
      "episode : 68\n",
      "log\n",
      "done\n",
      "epi: 68 | total_scores: -0.08767728507518768 | total_int_scores: 0.0028577246703207493 |\n",
      "episode : 69\n",
      "log\n",
      "done\n",
      "epi: 69 | total_scores: -0.08767719566822052 | total_int_scores: 0.00286641763523221 |\n",
      "episode : 70\n",
      "log\n",
      "done\n",
      "epi: 70 | total_scores: -0.0876678079366684 | total_int_scores: 0.0038051032461225986 |\n",
      "episode : 71\n",
      "log\n",
      "done\n",
      "epi: 71 | total_scores: -0.08768393099308014 | total_int_scores: 0.002192456740885973 |\n",
      "episode : 72\n",
      "log\n",
      "done\n",
      "epi: 72 | total_scores: -0.08769023418426514 | total_int_scores: 0.0015628822147846222 |\n",
      "episode : 73\n",
      "log\n",
      "done\n",
      "epi: 73 | total_scores: -0.08769100904464722 | total_int_scores: 0.0014847315615043044 |\n",
      "episode : 74\n",
      "log\n",
      "done\n",
      "epi: 74 | total_scores: -0.08769170939922333 | total_int_scores: 0.0014146333560347557 |\n",
      "episode : 75\n",
      "log\n",
      "done\n",
      "epi: 75 | total_scores: -0.08769680559635162 | total_int_scores: 0.0009054146939888597 |\n",
      "episode : 76\n",
      "log\n",
      "done\n",
      "epi: 76 | total_scores: -0.0876939594745636 | total_int_scores: 0.0011902274563908577 |\n",
      "episode : 77\n",
      "log\n",
      "done\n",
      "epi: 77 | total_scores: -0.0876917839050293 | total_int_scores: 0.0014067584415897727 |\n",
      "episode : 78\n",
      "log\n",
      "done\n",
      "epi: 78 | total_scores: -0.08768753707408905 | total_int_scores: 0.0018318420043215156 |\n",
      "episode : 79\n",
      "log\n",
      "done\n",
      "epi: 79 | total_scores: -0.08769238740205765 | total_int_scores: 0.0013470954727381468 |\n",
      "episode : 80\n",
      "log\n",
      "done\n",
      "epi: 80 | total_scores: -0.08769679814577103 | total_int_scores: 0.0009057821589522064 |\n",
      "episode : 81\n",
      "log\n",
      "done\n",
      "epi: 81 | total_scores: -0.08769647032022476 | total_int_scores: 0.0009386560413986444 |\n",
      "episode : 82\n",
      "log\n",
      "done\n",
      "epi: 82 | total_scores: -0.08767448365688324 | total_int_scores: 0.0031376853585243225 |\n",
      "episode : 83\n",
      "log\n",
      "done\n",
      "epi: 83 | total_scores: -0.08767811208963394 | total_int_scores: 0.0027744320686906576 |\n",
      "episode : 84\n",
      "log\n",
      "done\n",
      "epi: 84 | total_scores: -0.0876760184764862 | total_int_scores: 0.0029844283126294613 |\n",
      "episode : 85\n",
      "log\n",
      "done\n",
      "epi: 85 | total_scores: -0.0876886397600174 | total_int_scores: 0.0017219586297869682 |\n",
      "episode : 86\n",
      "log\n",
      "done\n",
      "epi: 86 | total_scores: -0.08767789602279663 | total_int_scores: 0.002796259243041277 |\n",
      "episode : 87\n",
      "log\n",
      "done\n",
      "epi: 87 | total_scores: -0.08767315000295639 | total_int_scores: 0.0032707189675420523 |\n",
      "episode : 88\n",
      "log\n",
      "done\n",
      "epi: 88 | total_scores: -0.08767877519130707 | total_int_scores: 0.002708412241190672 |\n",
      "episode : 89\n",
      "log\n",
      "done\n",
      "epi: 89 | total_scores: -0.08765555918216705 | total_int_scores: 0.005030431319028139 |\n",
      "episode : 90\n",
      "log\n",
      "done\n",
      "epi: 90 | total_scores: -0.08765515685081482 | total_int_scores: 0.005070265382528305 |\n",
      "episode : 91\n",
      "log\n",
      "done\n",
      "epi: 91 | total_scores: -0.0876944437623024 | total_int_scores: 0.001141142682172358 |\n",
      "episode : 92\n",
      "log\n",
      "done\n",
      "epi: 92 | total_scores: -0.08767879009246826 | total_int_scores: 0.0027064373716712 |\n",
      "episode : 93\n",
      "log\n",
      "done\n",
      "epi: 93 | total_scores: -0.08767645806074142 | total_int_scores: 0.002939882455393672 |\n",
      "episode : 94\n",
      "log\n",
      "done\n",
      "epi: 94 | total_scores: -0.08767831325531006 | total_int_scores: 0.002754418645054102 |\n",
      "episode : 95\n",
      "log\n",
      "done\n",
      "epi: 95 | total_scores: -0.08768026530742645 | total_int_scores: 0.002559394109994173 |\n",
      "episode : 96\n",
      "log\n",
      "done\n",
      "epi: 96 | total_scores: -0.08767028152942657 | total_int_scores: 0.00355827109888196 |\n",
      "episode : 97\n",
      "log\n",
      "done\n",
      "epi: 97 | total_scores: -0.08767639100551605 | total_int_scores: 0.002946937456727028 |\n",
      "episode : 98\n",
      "log\n",
      "done\n",
      "epi: 98 | total_scores: -0.08769378066062927 | total_int_scores: 0.0012076138518750668 |\n",
      "episode : 99\n",
      "log\n",
      "done\n",
      "epi: 99 | total_scores: -0.08768065273761749 | total_int_scores: 0.0025205304846167564 |\n"
     ]
    }
   ],
   "source": [
    "## episode\n",
    "for epi in range(num_episode) :\n",
    "    ## episode memory 선언\n",
    "    episode_buffer = deque(maxlen = 6000)\n",
    "\n",
    "    state = env.reset()\n",
    "    state = np.expand_dims(state, 0)\n",
    "    df_rand = env.get_state()\n",
    "    df_rand['action'] = 'done'\n",
    "\n",
    "    batch_loss, scores, int_scores, ext_scores = [],[],[],[]\n",
    "    \n",
    "    ## collect on-policy samples\n",
    "    step_cnt = 0\n",
    "    while True :\n",
    "        ########################\n",
    "        #### time step 진행 ####s\n",
    "        ########################\n",
    "        ## action 수행\n",
    "        action, operation, value = get_action(A2C, state, X_train)\n",
    "        print(action)\n",
    "\n",
    "        ## next state, reward, done 계산\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "        ext_scores.append(reward)\n",
    "\n",
    "        ## rnd networks update\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_sf = target_network(next_state)\n",
    "            prediction_sf = prediction_network(next_state)\n",
    "\n",
    "            predictor_loss = 0.5 * tf.square(tf.stop_gradient(target_sf) - prediction_sf)\n",
    "            predictor_loss = tf.reduce_mean(predictor_loss)\n",
    "\n",
    "            # 오류함수를 줄이는 방향으로 모델 업데이트\n",
    "            grads = tape.gradient(predictor_loss, prediction_network.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, prediction_network.trainable_variables))\n",
    "\n",
    "        ## intrinstic reward\n",
    "        int_reward = tf.norm(target_sf - prediction_sf)\n",
    "        reward += 0.01*int_reward\n",
    "\n",
    "        ## episode buffer에 transition 저장\n",
    "        episode_buffer.append([state, action, reward, next_state])\n",
    "\n",
    "        ## state에 next_state 할당\n",
    "        state = next_state\n",
    "        scores.append(reward)\n",
    "        int_scores.append(int_reward)\n",
    "\n",
    "        append_df = env.get_state()\n",
    "        append_df['action'] = action\n",
    "        df_rand = df_rand.append(append_df)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predict_actions, current_value = A2C(state)\n",
    "            _, next_value = A2C(next_state)\n",
    "            target = reward + (1 - done) * discount_factor * next_value\n",
    "\n",
    "            # 정책 신경망 오류 함수 구하기\n",
    "            advantage = tf.stop_gradient(target - current_value)\n",
    "\n",
    "            # 가치 신경망 오류 함수 구하기\n",
    "            critic_loss = 0.5 * tf.square(tf.stop_gradient(target) - current_value)\n",
    "            critic_loss = tf.reduce_mean(critic_loss)\n",
    "\n",
    "            # 정책 신경망 오류 함수 구하기\n",
    "            actions_ = tf.argmax(predict_actions, axis = 1)\n",
    "            one_hot_action = tf.one_hot([actions_], len(transformations), dtype = tf.float32)\n",
    "            action_probs = one_hot_action*predict_actions\n",
    "\n",
    "            cross_entropy_actions = tf.math.log(action_probs + 1e-5)\n",
    "            actor_loss_actions = - tf.reduce_mean(cross_entropy_actions * advantage)\n",
    "\n",
    "            total_loss = actor_loss_actions + critic_loss \n",
    "\n",
    "            # 오류함수를 줄이는 방향으로 모델 업데이트\n",
    "            grads = tape.gradient(total_loss, A2C.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, A2C.trainable_variables))\n",
    "        \n",
    "        step_cnt += 1    \n",
    "        if step_cnt > 5:\n",
    "            done = True\n",
    "\n",
    "        ############################\n",
    "        ### update replay buffer ###\n",
    "        ############################\n",
    "        if done :\n",
    "            ## sampling probability 계산\n",
    "            td_error = [x[2] + A2C.predict(x[3])[1][0][0] - A2C.predict(x[0])[1][0][0] for x in list(episode_buffer)]\n",
    "            priority = np.abs(td_error) + 1e-5\n",
    "            probability = priority/np.sum(priority)\n",
    "\n",
    "            ## episode buffer의 transition들을 호출 후 Discounted Reward와 TD-Error를 계산\n",
    "            for idx, transition in enumerate(episode_buffer) :\n",
    "                state, action, reward, next_state = transition\n",
    "                ## gain 계산\n",
    "                gain_e = gain(episode_buffer, idx)\n",
    "                replay_buffer.append([state, action, gain_e, next_state, td_error[idx]])\n",
    "\n",
    "            print(\"epi: {} | total_scores: {} | total_int_scores: {} |\".format(epi, np.sum(scores), np.sum(int_scores)))\n",
    "\n",
    "            if epi % 10 == 0 :\n",
    "                A2C.save_weights(weight_path+\"A2C_epi_{}.h5\".format(epi))\n",
    "                prediction_network.save_weights(weight_path+\"prediction_epi_{}.h5\".format(epi))\n",
    "            break\n",
    "\n",
    "    df_rand.to_csv(state_path + \"state_epi{}.csv\".format(epi), index = False)\n",
    "\n",
    "    #################################\n",
    "    ######### SIL learning ##########\n",
    "    #################################\n",
    "    if epi % 4 == 0 :\n",
    "        ## SIL trainig ##\n",
    "        #print(\"SIL learning\")\n",
    "        ## td error로 부터 sampling prob 계산\n",
    "        td_error = [x[4] for x in replay_buffer]\n",
    "        priority = np.abs(td_error) + 1e-5\n",
    "        probability = priority/np.sum(priority)\n",
    "\n",
    "        ## 확률로 256개 transition 계산\n",
    "        select_idx = np.random.choice([x for x in range(len(list(replay_buffer)))], size = 256, p = probability)\n",
    "        ## 선택\n",
    "        select_data = [replay_buffer[idx] for idx in select_idx]\n",
    "\n",
    "        for idx, (state,action,trans_R,next_state, prob) in enumerate(select_data) :\n",
    "            if idx == 0 :\n",
    "                state_set = state\n",
    "                action_set = action\n",
    "                R_set = trans_R\n",
    "                n_state_set = next_state\n",
    "                prob_set = prob\n",
    "\n",
    "            else :\n",
    "                state_set = np.vstack([state_set, state])\n",
    "                action_set = np.vstack([action_set, action])\n",
    "                R_set = np.vstack([R_set, trans_R])\n",
    "                n_state_set = np.vstack([n_state_set, next_state])\n",
    "                prob_set = np.vstack([prob_set, prob])\n",
    "\n",
    "        R = R_set.squeeze()\n",
    "        V = A2C.predict(state_set)[1].squeeze()\n",
    "        R_V = R-V\n",
    "        under_0 = [idx for idx,x in enumerate(R_V) if x < 0]\n",
    "\n",
    "        if len(under_0) == 0 :\n",
    "            pass\n",
    "        else :\n",
    "            ## A2C update\n",
    "            with tf.GradientTape() as tape:\n",
    "                predict_actions, current_value = A2C(state_set)\n",
    "                _, next_value = A2C(n_state_set)\n",
    "                target = R_set\n",
    "\n",
    "                # 정책 신경망 오류 함수 구하기\n",
    "                advantage = tf.stop_gradient(target - current_value)\n",
    "\n",
    "                # 가치 신경망 오류 함수 구하기\n",
    "                critic_loss = 0.5 * tf.square(tf.stop_gradient(target) - current_value)\n",
    "                critic_loss = tf.reduce_mean(critic_loss)\n",
    "\n",
    "                # 정책 신경망 오류 함수 구하기\n",
    "                actions_ = tf.argmax(predict_actions, axis = 1)\n",
    "                one_hot_action = tf.one_hot([actions_], len(transformations), dtype = tf.float32)\n",
    "                action_probs = one_hot_action*predict_actions\n",
    "\n",
    "                cross_entropy_actions = tf.math.log(action_probs + 1e-5)\n",
    "                actor_loss_actions = - tf.reduce_mean(cross_entropy_actions * advantage)\n",
    "\n",
    "                total_loss = actor_loss_actions + critic_loss \n",
    "\n",
    "                # 오류함수를 줄이는 방향으로 모델 업데이트\n",
    "                grads = tape.gradient(total_loss, A2C.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, A2C.trainable_variables))\n",
    "\n",
    "        #print(len(under_0)/256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1e498deb-2b4c-49ef-878d-a36bd246db6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24954382150340287"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate baseline score\n",
    "results = cross_val_score(model_ridge, env.next_raw, y_train, cv=kfold, scoring=make_scorer(rae, greater_is_better=True))\n",
    "after_score = np.mean(results); after_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "09aea573-e6bd-4531-bb16-cb48cc4e3c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2933967504320455"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf026c-0904-4a7e-ad57-933ba8929077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
